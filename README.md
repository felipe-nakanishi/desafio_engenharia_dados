# Desafio Engenharia de Dados

## :nerd_face: DescriÃ§Ã£o do projeto

> O objetivo do projeto Ã© realizar uma POC (proof of concept) para o desenvolvimento de um novo datalake para a empresa SiCooperative LTDA. A primeira estrutura a ser considerada e que foi utilizada para este projeto Ã© a de movimentaÃ§Ã£o de cartÃµes.

## ğŸ“Œ Ãndice
- [Sobre o Projeto](#-sobre-o-projeto)
- [Arquitetura de Dados](#-arquitetura-de-dados)
- [Melhorias Futuras](#-melhorias-futuras)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Como Rodar o Projeto](#-como-rodar-o-projeto)
- [Imagens e Diagramas](#-imagens-e-diagramas)

---

## ğŸ“– Sobre o Projeto

ğŸ“Œ A SiCooperative LTDA. enfrenta um problema de velocidade e assertividade na tomada de decisÃµes causada pela ineficiÃªncia na disponibilizaÃ§Ã£o de informaÃ§Ãµes, hoje muito tempo Ã© perdido na criaÃ§Ã£o de relatÃ³rios individuais e na tentativa de correlacionÃ¡-los manualmente.

> Este projeto tem como objetivo ser o primeiro passo para o desenvolvimento de um datalake que possibilitarÃ¡ a centralizaÃ§Ã£o de informaÃ§Ãµes estratÃ©gicas.

> A estrutura de cartÃµes segue a seguinte estrutura:

![tabela_silver](img/tabelas_silver.png)

> O objetivo Ã© modelar esta estrutura em um banco de dados e ao final exportar um arquivo .csv com a seguinte estrutura:

![tabela_gold](img/tabela_gold.png)


Foram utilizados arquivos ficticios de diversos formatos como fonte de dados para a ingestÃ£o no banco de dados, a ideia foi simular as diversas fontes de dados que existem em um cenÃ¡rio real:

- associado: associado.csv
- cartÃ£o: cartao.json
- conta: conta.xml
- movimento do cartÃ£o: movimento.parquet

Foi utilizado a arquitetura medallion em camadas bronze, silver e gold para divisÃ£o lÃ³gica de camadas.

---

## :building_construction: Arquitetura de Dados

> A arquitetura de dados proposta para esta primeira estrutura de cartÃµes Ã© a seguinte:

![arquitetura](img/arquitetura.png)

- PostgreSQL: A escolha se deu pela sua confiabilidade e escalabilidade.
- Spark: Framework de processamento distribuido para big data de alta performance e escalabilidade.
- Python: Linguagem de fÃ¡cil manutenÃ§Ã£o e que se conecta facilmente com o Spark, PostgreSQL e outras ferramentas e framework de dados.

## :rocket: Melhorias Futuras

Para uma melhoria futura da arquitetura a recomendaÃ§Ã£o Ã© a adiÃ§Ã£o das seguintes ferramentas:

- OrquestraÃ§Ã£o: Apache Airflow para controlar e automatizar a pipeline de dados e execuÃ§Ã£o de scripts.
- Processamento Real-Time: Apache Kafka para casos como prevenÃ§ao Ã  fraudes um framework real-time Ã© importante.
- SeguranÃ§a e controle de acesso: Implementar um controle por roles no PostgreSQL por usuÃ¡rio.
- Cloud: Pode-se migrar a arquitetura para a nuvem AWS dado sua escalabilidade e menor custo.

## ğŸ›  Tecnologias Utilizadas

As principais tecnologias usadas no projeto sÃ£o:

- **ğŸ›  Linguagem:** Python 3.9
- **ğŸ“Š Data Pipeline:** Apache Spark
- **ğŸ›¢ Banco de Dados:** PostgreSQL
- **ğŸ³ Containers:** Docker e Docker Compose

---

## ğŸš€ Como Rodar o Projeto

### **1ï¸âƒ£ PrÃ©-requisitos**
Antes de iniciar, instale:
- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

### **2ï¸âƒ£ Clone o repositÃ³rio**
```sh
git clone https://github.com/seu-usuario/seu-projeto.git
cd seu-projeto


![Diagrama do Projeto](img/arquitetura.png)
