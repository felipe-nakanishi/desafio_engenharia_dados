# Desafio Engenharia de Dados

## :nerd_face: Descri√ß√£o do projeto

> O objetivo do projeto √© realizar uma POC (proof of concept) para o desenvolvimento de um novo datalake para a empresa SiCooperative LTDA. A primeira estrutura a ser considerada e que foi utilizada para este projeto √© a de movimenta√ß√£o de cart√µes.

## üìå √çndice
- [Sobre o Projeto](#-sobre-o-projeto)
- [Arquitetura de Dados](#-arquitetura-de-dados)
- [Melhorias Futuras](#-melhorias-futuras)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Como Rodar o Projeto](#-como-rodar-o-projeto)
- [Imagens e Diagramas](#-imagens-e-diagramas)

---

## üìñ Sobre o Projeto

üìå A SiCooperative LTDA. enfrenta um problema de velocidade e assertividade na tomada de decis√µes causada pela inefici√™ncia na disponibiliza√ß√£o de informa√ß√µes, hoje muito tempo √© perdido na cria√ß√£o de relat√≥rios individuais e na tentativa de correlacion√°-los manualmente.

> Este projeto tem como objetivo ser o primeiro passo para o desenvolvimento de um datalake que possibilitar√° a centraliza√ß√£o de informa√ß√µes estrat√©gicas.

> A estrutura de cart√µes segue a seguinte estrutura:

![tabela_silver](img/tabelas_silver.png)

> O objetivo √© modelar esta estrutura em um banco de dados e ao final exportar um arquivo .csv com a seguinte estrutura:

![tabela_gold](img/tabela_gold.png)


Foram utilizados arquivos ficticios de diversos formatos como fonte de dados para a ingest√£o no banco de dados, a ideia foi simular as diversas fontes de dados que existem em um cen√°rio real:

- associado: associado.csv
- cart√£o: cartao.json
- conta: conta.xml
- movimento do cart√£o: movimento.parquet

Foi utilizado a arquitetura medallion em camadas bronze, silver e gold para divis√£o l√≥gica de camadas.

---

## :building_construction: Arquitetura de Dados

> A arquitetura de dados proposta para esta primeira estrutura de cart√µes √© a seguinte:

![arquitetura](img/arquitetura.png)

- PostgreSQL: A escolha se deu pela sua confiabilidade e escalabilidade.
- Spark: Framework de processamento distribuido para big data de alta performance e escalabilidade.
- Python: Linguagem de f√°cil manuten√ß√£o e que se conecta facilmente com o Spark, PostgreSQL e outras ferramentas e framework de dados.

## :rocket: Melhorias Futuras

Para uma melhoria futura da arquitetura a recomenda√ß√£o √© a adi√ß√£o das seguintes ferramentas:

- Orquestra√ß√£o: Apache Airflow para controlar e automatizar a pipeline de dados e execu√ß√£o de scripts.
- Processamento Real-Time: Apache Kafka para casos como preven√ßao √† fraudes um framework real-time √© importante.
- Seguran√ßa e controle de acesso: Implementar um controle por roles no PostgreSQL por usu√°rio.
- Cloud: Pode-se migrar a arquitetura para a nuvem AWS dado sua escalabilidade e menor custo.

## üõ† Tecnologias Utilizadas

As principais tecnologias usadas no projeto s√£o:

- **üõ† Linguagem:** Python 3.9
- **üìä Data Pipeline:** Apache Spark
- **üõ¢ Banco de Dados:** PostgreSQL
- **üê≥ Containers:** Docker e Docker Compose

---

## üöÄ Como Rodar o Projeto

### **1Ô∏è‚É£ Pr√©-requisitos**
Antes de iniciar, instale:
- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

#### Para rodar o container siga o seguinte passo a passo:

> Abrir o terminal e digitar:

- cd caminho_do_diretorio
- docker-compose build --no-cache
- docker-compose up -d

### **2Ô∏è‚É£ Clone o reposit√≥rio**
```sh
git clone https://github.com/seu-usuario/seu-projeto.git
cd seu-projeto


![Diagrama do Projeto](img/arquitetura.png)
